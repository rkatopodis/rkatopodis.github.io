---
title: "Functional Gradient Descent for n-Tuple Regression"
collection: publications
permalink: /publication/functional-gradient-descent-n-tuple-regression
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2021-10-09
venue: '29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning'
paperurl: 'http://rkatopodis.github.io/files/esann2021_rafael_katopodis_camera_ready.pdf'
citation: 'Your Name, You. (2021). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
Abstract: n-tuple neural networks have been in the past applied to a wide range of learning domains. However, for the particular area of regression, existing systems have displayed two shortcomings: little flexibility in the objective function being optimized and an inability to handle nonstationarity in an online learning setting. A novel n-tuple system is proposed to address these issues. The new architecture leverages the idea of functional gradient descent, drawing inspiration from its use in kernel methods. Furthermore, its capabilities are showcased in two reinforcement learning tasks, which involves both nonstationary online learning and task-specific objective functions.

[Download paper here](http://rkatopodis.github.io/files/esann2021_rafael_katopodis_camera_ready.pdf)

Recommended citation: <b>Katopodis, R. F.</b> ; Lima, P. M. V. ; Fran√ßa, F. M. G. . Functional Gradient Descent for n-Tuple Regression. In: European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, 2021, Bruges. Proc of ESANN 2021. Brussels: i6doc.com, 2021. p. 505-511.